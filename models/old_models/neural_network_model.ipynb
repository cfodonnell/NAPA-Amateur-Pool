{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('C:\\\\Users\\\\Owner\\\\Napa\\\\results_model_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_assign(win_margin):\n",
    "    # This function converts the win_margin column into a binary win/loss result\n",
    "    if win_margin>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # Computes the sigmoid function for logistic regression\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    # Computes the gradient of the sigmoid function, to be used in backpropagation\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    # Calculate the hypothesis using input values of theta for each stage of the network\n",
    "    m = X.shape[0]\n",
    "    # Insert bias unit for input layer\n",
    "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)   \n",
    "    z2 = a1 * theta1.T\n",
    "    # Insert bias unit for hidden layer\n",
    "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
    "    z3 = a2 * theta2.T\n",
    "    h = sigmoid(z3)\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(params, input_layer_size, hidden_layer_size, num_labels, X, y):\n",
    "\n",
    "    # Reshape the parameter array back into the respective matrices\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_layer_size * (input_layer_size + 1)], (hidden_layer_size, (input_layer_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_layer_size * (input_layer_size + 1):], (num_labels, (hidden_layer_size + 1))))\n",
    "    \n",
    "    # Forward propagate through the network\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # Initialize\n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)\n",
    "    delta2 = np.zeros(theta2.shape)\n",
    "    \n",
    "    # Compute cost\n",
    "    first = np.multiply(-y, np.log(h))\n",
    "    second = np.multiply((1 - y), np.log(1 - h))\n",
    "    J = np.sum(first - second) / m\n",
    "    \n",
    "    # Backpropagate to get gradients   \n",
    "    d3 = h - y\n",
    "    d2 = np.multiply((d3*theta2[:,1:hidden_layer_size+1]), sigmoid_gradient(z2))  \n",
    "    delta1 = (np.matmul(a1.T, d2)).T / m\n",
    "    delta2 = (np.matmul(d3.T, a2)) / m\n",
    "    \n",
    "    # Reshape gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race Margin</th>\n",
       "      <th>Win % Margin</th>\n",
       "      <th>Skill Margin</th>\n",
       "      <th>Game Margin</th>\n",
       "      <th>AvgPPM Margin</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.805556</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.583333</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.545455</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Race Margin  Win % Margin  Skill Margin  Game Margin  AvgPPM Margin  Result\n",
       "0          2.0      3.750000            33            0           1.90       1\n",
       "1          1.0    -11.805556            14            0          -1.19       1\n",
       "2          0.0     -9.583333             7            0          -0.30       1\n",
       "3         -2.0     10.000000           -10            0           2.72       1\n",
       "4          1.0     14.545455            18            0           3.48       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new binary column to the data, which has value 1 where the result is positive, and 0 if negative\n",
    "data['Result'] = data.apply(lambda x: result_assign(x['Win Margin']),axis=1)\n",
    "# Select only quantitive paramaters to be used in the model\n",
    "model_data = data[['Race Margin', 'Win % Margin', 'Skill Margin', 'Game Margin', 'AvgPPM Margin', 'Result']]\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X (training data) and y (target variable)\n",
    "cols = model_data.shape[1]\n",
    "X = model_data.iloc[:,0:cols-1]\n",
    "y = model_data.iloc[:,cols-1:cols]\n",
    "y0 = y\n",
    "# Split the data into training and validation sets with 80/20 ratio\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state = 0)\n",
    "\n",
    "# Convert to numpy matrices\n",
    "m = X.shape[0]\n",
    "X_train = np.matrix(train_X)\n",
    "y_train = np.matrix(train_y)\n",
    "X_val = np.matrix(val_X)\n",
    "y_val = np.matrix(val_y)\n",
    "\n",
    "# Define architecture of neural network\n",
    "input_layer_size  = cols-1;  # Each match has 5 features\n",
    "hidden_layer_size = 50;      # 50 hidden units\n",
    "num_labels = 1;              # Win/Loss parameter\n",
    "\n",
    "# Randomly initialize the input parameter array, with values normalized by length\n",
    "epsilon_1 = np.sqrt(6./(hidden_layer_size + input_layer_size))\n",
    "epsilon_2 = np.sqrt(6./(hidden_layer_size + num_labels))\n",
    "param1 = np.random.random(size=hidden_layer_size * (input_layer_size + 1))*2*epsilon_1 - epsilon_1\n",
    "param2 = np.random.random(size=num_labels * (hidden_layer_size + 1))*2*epsilon_2 - epsilon_2\n",
    "params = np.concatenate((param1,param2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 63.0615453729%\n",
      "Validation accuracy = 63.3123689727%\n"
     ]
    }
   ],
   "source": [
    "# Minimize the backpropagation cost function\n",
    "fmin = minimize(fun=backward_prop, x0=params, args=(input_layer_size, hidden_layer_size, num_labels, X_train, y_train), \n",
    "                method='TNC', jac=True, options={'maxiter': 250})\n",
    "\n",
    "# Retrieve the corresponding theta parameters and reshape to matrices\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_layer_size * (input_layer_size + 1)], (hidden_layer_size, (input_layer_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_layer_size * (input_layer_size + 1):], (num_labels, (hidden_layer_size + 1))))\n",
    "\n",
    "# Calculate predictions based on the model\n",
    "a1_t, z2_t, a2_t, z3_t, h_t = forward_propagate(X_train, theta1, theta2)\n",
    "a1_v, z2_v, a2_v, z3_v, h_v = forward_propagate(X_val, theta1, theta2)\n",
    "y_pred_train = [1 if i>=0.5 else 0 for i in h_t]\n",
    "y_pred_val = [1 if i>=0.5 else 0 for i in h_v]\n",
    "\n",
    "# Compare predictions to actual data\n",
    "correct_train = [1 if a == b else 0 for (a, b) in zip(y_pred_train, y_train)]\n",
    "correct_val = [1 if a == b else 0 for (a, b) in zip(y_pred_val, y_val)]\n",
    "accuracy_train = (sum(map(int, correct_train)) / float(len(correct_train)))\n",
    "accuracy_val = (sum(map(int, correct_val)) / float(len(correct_val)))\n",
    "print 'Train accuracy = {0}%'.format(accuracy_train * 100)\n",
    "print 'Validation accuracy = {0}%'.format(accuracy_val * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
